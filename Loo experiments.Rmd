---
title: "LOO experiments"
author: "Anthony Staines"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    toc: true
    fig_caption: true
    number_sections: true
    latex_engine: xelatex
  word_document: default
  html_document: default
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: vancouver.csl
---

```{r Clean environment, include = FALSE}
  rm(list = ls())
```

```{r setup, include=FALSE}
library(rstanarm)
library(tidybayes)
library(posterior)
library(projpred)

library(tidyverse)
library(bayesplot)
library(bayestestR)

library(tidybayes)
library(lubridate)
library(tibble)
library(tidymodels)
library(readxl)

library(lme4)

library(knitr)
library(kableExtra)
library(summarytools)

library(patchwork)
library(dotwhisker)
library(ggdist)

library(ranger)
library(mlr3verse)
library(mlr3viz)

library(data.table)
library(future)

library(sjPlot)
library(sjtable2df)

library(broom)
library(broom.mixed)

library(matrixStats)

tidymodels_prefer(quiet = TRUE)
st_options(ctable.round.digits = 2)

#How many CPU's?
N = parallel::detectCores()
  options(Ncpus = N - 1)
  options(mc.cores = N - 1)
  setDTthreads(threads = N - 1,
               restore_after_fork = TRUE,
               throttle = 1024)

options(dplyr.summarise.inform = FALSE, # shut up summarise
        ranger.num.threads = N - 1) # Prepare for rf models

knitr::opts_chunk$set(
	echo = FALSE,
	fig.pos = "H",
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	cache.extra = knitr::rand_seed,
	cache.lazy = FALSE
)
rm(N)
```

Load data

```{r Load existing data}
HIPE <- readRDS('data/HIPE.Rds')
CCH <- readRDS('data/CCH.Rds')
#glimpse(CCH)

# STAN does not like character variables, so we turn them into factors (No =  0, and  Yes = 1, more or less.

CCH <- CCH |>
  mutate(across(where(is.character), ~as_factor(.)))  |>
  rowid_to_column(var = 'rowid')
#glimpse(CCH)

HIPE <- HIPE |>
  mutate(across(where(is.character), ~as_factor(.))) |>
  rowid_to_column('rowid') # Add a rowid variable

#glimpse(HIPE)

#table(CCH$PN) # 79 positive out of 1,000
```


Pick one model, and play with it.

```{r Load a model etc.}
tsk.PNk <- readRDS('data/tsk.PNk')
df.train.PMk <- readRDS('data/df.train.PNk')
fit.PNk <- readRDS('data/fit.PNk')

```

```{r get_refmodel - fails}
#get_refmodel(fit.PNk)
#Error in get_refmodel.stanreg(fit.PNk) : 
#  In case of the binomial family, projpred cannot handle observation weights (apart from the numbers of trials).
#3. stop("In case of the binomial family, projpred cannot handle observation ",
#"weights (apart from the numbers of trials).")
#2. get_refmodel.stanreg(fit.PNk)
#1. get_refmodel(fit.PNk)

```

Original fit

# Bayesian fit

We use a common mildly informative prior.

```{r t_prior}
  t_prior <- student_t(df = 7, location = 0, scale = 2.5)
```

We fit the models (this takes some little time, as there are 10)

```{r Rstanarm model fits}
# ancillary functions
# 
# Create the formula needed for stan_glm
# 
make_formula <- function(df.TSK) {
  names <- names(df.TSK)
  N = length(df.TSK)
  Formula = paste( names[3], ' ~ ',
                   paste(c(names[4:N]),
                         collapse = ' + ')) # This is the formula needed for the fit
  return(Formula)
}
#
# Fit and save the desired model
#
fit.task <- function(df.train){
  model_name <- deparse(substitute(df.train))
  model_name <- str_split_i(model_name,
                            pattern = '\\.', # Cut on .
                            i = -1) # Last element

  fit <- stan_glm(make_formula(df.train),
                 data = df.train,
                 family = binomial(link = "logit"),
                 weights = Weights,
                 prior = t_prior, prior_intercept = t_prior,
                 cores = 6, seed = 12345,
                 chains = 6,
                 iter = 6000, warmup = 2000,
                 refresh = 0 ) # Quietly!

  saveRDS(fit, file = paste0('data/fit.', model_name))

return(fit)
}

fit.PNk <- fit.task(df.train.PNk)

```

Revised fit

```{r Rstanarm model revised fits}
# ancillary functions
#
# Fit and save the desired model
#
fit.task <- function(df.train, Adapt_Delta = NULL){
  model_name <- deparse(substitute(df.train))
  model_name <- str_split_i(model_name,
                            pattern = '\\.', # Cut on .
                            i = -1) # Last element
  #Regularise hs prior
  D <- length(df.train) - 3 # Terms in regression formula
  P <- 6 # Guess at number of relevant terms
  N <- nrow(df.train)
  tau0 <- (P/(D-P))* (1/sqrt(N))

  fit <- stan_glm(make_formula(df.train),
                 data = df.train,
                 family = binomial(link = "logit"),
                 weights = Weights,
                 prior = hs(global_scale = tau0),
#                 prior = t_prior,
                 prior_intercept = t_prior,
                 adapt_delta = Adapt_Delta,
                 cores = 6, seed = 12345,
                 chains = 6,
                 iter = 6000, warmup = 2000,
                 refresh = 0 ) # Quietly!

  saveRDS(fit, file = paste0('data/fit.', model_name))

return(fit)
}

fit.hs.PNk <- fit.task(df.train.PNk, Adapt_Delta = 0.999)

```
# Model tests

First we run a series of pretty routine diagnostics for each of the 10 models

```{r diagnostic measures for each model}
kable(bayestestR::diagnostic_posterior(fit.PNk), caption = 'Diagnostics for PNk model')

kable(bayestestR::diagnostic_posterior(fit.hs.PNk), caption = 'Diagnostics for PNk.hs model')

```

Then we prepare a set of 10 dot and whisker plots to visually display the point estimates and the uncertainty (HDI) for each parameter in each model.

```{r Dot and Whisker plots of parameter estimates from each model}
make_dwPlot_fit <- function(fit) {
  model_name <- deparse(substitute(fit))
  model_name <-
    str_split_i(model_name,
              pattern = '\\.', # Cut on .
              i = -1) # Last element

pe <- point_estimate(fit, centrality = 'mean')
hdi <- ci(fit, method = 'hdi') |>
    full_join(pe,
              by = join_by(Parameter, Effects, Component)) |>
     rename(estimate = Mean) |>
     rename(term = Parameter) |>
     rename(conf.low = CI_low) |>
     rename(conf.high = CI_high)

Graph <- dwplot(hdi,  vline = geom_vline(
        xintercept = 0,
        colour = "red",
        linetype = 2), # plot line at zero _behind_ coefs
    whisker_args = list(size = 1, colour = 'green')) +
  theme_minimal() +
  labs( title = paste0('Parameter estimates for ', model_name),
        y = 'Item', x = 'Effect size') +
  guides(colour = 'none')

Graph

ggsave(filename =
      paste0('image/Dot_plot_fit_', model_name, '.pdf'),
       height = 10, width = 15, dpi = 1200)

return(Graph)
}

dw_PNk      <- make_dwPlot_fit(fit.PNk)
dw_PNk

dw_PNk_hs   <- make_dwPlot_fit(fit.hs.PNk)
dw_PNk_hs

rm( list = ls()[str_detect(ls(),'dw_.')])
```

We do live interactive testing of model fit, which proves satisfactory, suggesting good mixing of all chains, no issues with divergence, and no other striking anomalies.

```{r Rstanarm model checks in shinystan, eval = FALSE}
conflicted::conflicts_prefer(shiny::observe)

launch_shinystan(fit.PNk, ppd = TRUE) # Allows me to check fit etc.
launch_shinystan(fit.hs.PNk, ppd = TRUE) # Allows me to check fit etc.

```


```{r multiply rows}
CCH$W <- round(CCH$Weights,0)
table(CCH$W)

CCH_expanded <- purrr::map_dfr(seq_len(CCH$W), ~CCH) |>
    select(rowid, Weights, W) |>
    arrange(W, rowid) # No
CCH

CCH_expanded <- as.data.frame(lapply(CCH, rep, CCH$W)) |>
    select(rowid, Weights, W) |>
    arrange(W, rowid) # Yes

CCH_expanded <- CCH %>% slice(rep(seq(n()), W)) |>
    select(rowid, Weights, W) |>
    arrange(W, rowid) # Yes

```
